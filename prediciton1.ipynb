{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "prediciton1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zilipp/FakeNewsNet/blob/master/prediciton1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "01f361ddc47e0b386595316fe3d7f4dabbd260db",
        "id": "XE0VGEF8ZA6M",
        "colab_type": "text"
      },
      "source": [
        "# Abusive Language Online \n",
        "\n",
        "Predition1: predict OFF/NOT\n",
        "\n",
        "* Upload it each time: Dataset: [data](http://demo.clab.cs.cmu.edu/ethical_nlp2019/homeworks/hw3/hw3.html)\n",
        "\n",
        "\n",
        "1.   train.tsv\n",
        "2.   dev.tsv\n",
        "3.   test.tsv\n",
        "\n",
        "* Need manually add log.txt\n",
        "* Mount drive to load GloVe embeddings\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqazyGPwaTEe",
        "colab_type": "text"
      },
      "source": [
        "# Import useful lib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "ONg01KM4ZA6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "from logging import handlers\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import time\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import random \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, CuDNNLSTM, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhWzw5Rtajm7",
        "colab_type": "text"
      },
      "source": [
        "# Prepare logging file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEM02jMKdZtk",
        "colab_type": "code",
        "outputId": "bf0f4f4a-3a18-4d1c-ce6f-558991dfdf17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vggd1S4jZA6R",
        "colab_type": "code",
        "outputId": "1936347d-4b59-43f8-8b3d-847c5f13a730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "def init_logger(log_file):\n",
        "    if not os.path.exists(log_file):\n",
        "        os.makedirs(os.path.dirname(log_file))\n",
        "\n",
        "    log = logging.getLogger('')\n",
        "    log.setLevel(logging.INFO)\n",
        "    output_format = logging.Formatter(fmt='%(asctime)s %(levelname)-8s %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
        "    std_out_handler = logging.StreamHandler(sys.stdout)\n",
        "    std_out_handler.setFormatter(output_format)\n",
        "    logging.getLogger().addHandler(std_out_handler)\n",
        "    file_handler = logging.handlers.RotatingFileHandler(log_file, maxBytes=(1048576*5), backupCount=7)\n",
        "    file_handler.setFormatter(output_format)\n",
        "    logging.getLogger().addHandler(file_handler)\n",
        "\n",
        "init_logger('gdrive/My Drive/Colab Notebooks/246Project/log.txt')\n",
        "logging.info('=============start=================')\n",
        "logging.info('logging file prepared')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-07 00:11:46 INFO     =============start=================\n",
            "2020-05-07 00:11:46 INFO     =============start=================\n",
            "2020-05-07 00:11:46 INFO     =============start=================\n",
            "2020-05-07 00:11:46 INFO     =============start=================\n",
            "2020-05-07 00:11:46 INFO     logging file prepared\n",
            "2020-05-07 00:11:46 INFO     logging file prepared\n",
            "2020-05-07 00:11:46 INFO     logging file prepared\n",
            "2020-05-07 00:11:46 INFO     logging file prepared\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11l-8APTaOVP",
        "colab_type": "text"
      },
      "source": [
        "# Data proprecessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaD_vgEytb9u",
        "colab_type": "text"
      },
      "source": [
        "## Reading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flhVY6tUu-wN",
        "colab_type": "code",
        "outputId": "6d094e81-c932-452f-b4db-ec55cd3668aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SokHSWetCXCo",
        "colab_type": "code",
        "outputId": "679b3038-e697-4c96-dfc2-b3147e871bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%cd gdrive/My\\ Drive/Abusive_language_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/My Drive/Abusive_language_data'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhfBBtlIHN6p",
        "colab_type": "code",
        "outputId": "76dcb239-852a-4432-ed1a-064ebbf81ee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "# Clone github repository setup\n",
        "# import join used to join ROOT path and MY_GOOGLE_DRIVE_PATH\n",
        "from os.path import join  \n",
        "\n",
        "# path to your project on Google Drive\n",
        "MY_GOOGLE_DRIVE_PATH = 'My Drive/246_Project' \n",
        "# replace with your Github username \n",
        "GIT_USERNAME = \"kruttikajain\" \n",
        "# definitely replace with your\n",
        "GIT_TOKEN = \"5fae1c9f18e3a0c680bf35e9ef63c72308ef2b4c\"  \n",
        "# Replace with your github repository in this case we want \n",
        "# to clone deep-learning-v2-pytorch repository\n",
        "GIT_REPOSITORY = \"Targetted-Abusive_Language_Online\" \n",
        "\n",
        "PROJECT_PATH = join(ROOT, MY_GOOGLE_DRIVE_PATH)\n",
        "\n",
        "# It's good to print out the value if you are not sure \n",
        "print(\"PROJECT_PATH: \", PROJECT_PATH)   \n",
        "\n",
        "# In case we haven't created the folder already; we will create a folder in the project path \n",
        "!mkdir \"{PROJECT_PATH}\"    \n",
        "\n",
        "#GIT_PATH = \"https://{GIT_TOKEN}@github.com/{GIT_USERNAME}/{GIT_REPOSITORY}.git\" this return 400 Bad Request for me\n",
        "GIT_PATH = \"https://\" + GIT_TOKEN + \"@github.com/\" + GIT_USERNAME + \"/\" + GIT_REPOSITORY + \".git\"\n",
        "print(\"GIT_PATH: \", GIT_PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a8d72646e184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mGIT_REPOSITORY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Targetted-Abusive_Language_Online\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mPROJECT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMY_GOOGLE_DRIVE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# It's good to print out the value if you are not sure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ROOT' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOtNdORiaKqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    logging.info('loading the dataset...')\n",
        "    train_df = pd.read_csv(\"./train.tsv\", sep=\"\\t\")\n",
        "    val_df = pd.read_csv(\"./dev.tsv\", sep=\"\\t\")\n",
        "    test_df = pd.read_csv(\"./test.tsv\", sep=\"\\t\")\n",
        "    \n",
        "    # shape of df, column names\n",
        "    logging.info('Train shape : ' + str(train_df.shape)) # 'text', 'label', 'category'\n",
        "    logging.info('Val shape: ' + str(val_df.shape))\n",
        "    logging.info('Test shape: ' + str(test_df.shape))\n",
        "    \n",
        "    logging.info('train_df.columns: ' + train_df.columns)\n",
        "    logging.info('val_df.columns: ' + val_df.columns)\n",
        "    logging.info('test_df.columns: ' + test_df.columns)\n",
        "\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "train_df, val_df, test_df = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO55Z3UaXUsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApWoZxt1dc-a",
        "colab_type": "text"
      },
      "source": [
        "**Attributes in data:**\n",
        "\n",
        "\n",
        "***Trainning data:***  (10592, 3) \\\\\n",
        "\n",
        "* **text:** \\\\\n",
        "tweet content\n",
        "\n",
        "* **label:** \\\\\n",
        "1.   (NOT) Not Offensive - This post does not contain offense or profanity\n",
        "2.   (OFF) Offensive - This post contains offensive language or a targeted (veiled or direct) offense\n",
        "\n",
        "* **category:** (if label is 'OFF') \\\\\n",
        "1.   (TIN) Targeted Insult and Threats - A post containing an insult or threat to an individual, a group, or others\n",
        "2.   (UNT) Untargeted - A post containing non-targeted profanity and swearing.\n",
        "\n",
        "***Validation data:***  (1324, 3) \\\\\n",
        "\n",
        "***Testing data***:  'text' (1324, 1) \\\\\n",
        "* **text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEJfFD-hkhu5",
        "colab_type": "text"
      },
      "source": [
        "## Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g52M8qtkk36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_cleaning(train_df, val_df, test_df):\n",
        "    # shuffle data\n",
        "    train_df = train_df.sample(frac=1, random_state=2020).reset_index(drop=True)\n",
        "    \n",
        "    # lo lowercae\n",
        "    train_df['text'] = train_df['text'].str.lower()\n",
        "    val_df['text'] = val_df['text'].str.lower()\n",
        "    test_df['text'] = test_df['text'].str.lower()\n",
        "\n",
        "    # delete \"noise words\"\n",
        "    noise = [\"url\",\"user\",\"@\",\"&amp;\",\"#\",\"-\",'.',\"!\",\"?\",\"rt\",\"dm\",\"retweet\",\"rt\",\"dm\"]\n",
        "    for WORD in noise:\n",
        "        train_df['text'] = train_df['text'].str.replace(WORD, '')\n",
        "        val_df['text'] = val_df['text'].str.replace(WORD, '')\n",
        "        test_df['text'] = test_df['text'].str.replace(WORD, '')\n",
        "\n",
        "    # change label to 0/a\n",
        "    train_df['label'] = train_df['label'].map({'OFF': 1, 'NOT': 0})\n",
        "    val_df['label'] = val_df['label'].map({'OFF': 1, 'NOT': 0})\n",
        "\n",
        "    # one-hot encoding of category\n",
        "    train_df = pd.concat([train_df,pd.get_dummies(train_df['category'], prefix='category')],axis=1)\n",
        "    train_df.drop(['category'],axis=1, inplace=True)\n",
        "    \n",
        "    val_df = pd.concat([val_df,pd.get_dummies(val_df['category'], prefix='category')],axis=1)\n",
        "    val_df.drop(['category'],axis=1, inplace=True)\n",
        "    return train_df, val_df, test_df\n",
        "\n",
        "train_df, val_df, test_df = data_cleaning(train_df, val_df, test_df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muL8B6aXSu3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwBBjRW0-Ubf",
        "colab_type": "text"
      },
      "source": [
        "Check the content of abusive text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6em0dtx8D3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "abusive_df = train_df.loc[train_df['label'] == 1]\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "abusive_df['text'].head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plq9OgoGtqb8",
        "colab_type": "text"
      },
      "source": [
        "## Data distribution and visualization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKV_v3kvlmg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# count how many letters in a sentence\n",
        "def label_distribution(train_df):\n",
        "    #  length of text\n",
        "    count = train_df['text'].str.split().apply(len).value_counts()\n",
        "    count.sort_index(inplace=True)\n",
        "    count.index = count.index.astype(str) + ' words:'\n",
        "    # logging.info(count[0:5])\n",
        "    # logging.info(count[-5:])\n",
        "    plt.plot(range(len(count)), count, color='blue')\n",
        "    plt.title(\"Text length\")\n",
        "    plt.show()\n",
        "    # label distribution\n",
        "    logging.info('number of label = 1 : ' + str((train_df['label'] != 0).sum()))\n",
        "    logging.info('number of category_TIN = 1: ' + str((train_df['category_TIN'] != 0).sum()))\n",
        "    logging.info('number of category_UNT = 1: ' + str((train_df['category_UNT'] != 0).sum()))\n",
        "\n",
        "    # plot histogram\n",
        "    train_df['label'].plot.hist(bins=2, title='label distribution')\n",
        "    plt.show()\n",
        "\n",
        "label_distribution(train_df)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwxnd29E0lLP",
        "colab_type": "text"
      },
      "source": [
        "**Property of dataset**\n",
        "\n",
        "*   **Length of text:** [2, 60]\n",
        "\n",
        "*   **label:** \n",
        "1.   label = 0: 7072\n",
        "2.   label = 1: 3520\n",
        "\n",
        "* Among label = 1: \\\\\n",
        "1.   category_TIN = 1: 3089\n",
        "2.   category_UNT = 1: 431\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VD0DcUi-mGZ",
        "colab_type": "text"
      },
      "source": [
        "Word cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouIzGaJMZA6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word cloud\n",
        "normal_df = train_df.loc[train_df.label == 0]\n",
        "abusive_df = train_df.loc[train_df.label == 1]\n",
        "\n",
        "normal_text_array = np.array(normal_df['text'])\n",
        "abusive_text_array = np.array(abusive_df['text'])\n",
        "\n",
        "normal_text = ''.join(normal_text_array)\n",
        "abusive_text = ''.join(abusive_text_array)\n",
        "\n",
        "logging.info(\"convert to text finished\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfupiI1PZA6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normal\n",
        "wordcloud = WordCloud(background_color=\"white\").generate(normal_text)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# abusive\n",
        "wordcloud = WordCloud(background_color=\"white\").generate(abusive_text)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6rcUOlh_IOy",
        "colab_type": "text"
      },
      "source": [
        "Delete some common words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In65Isr_Am-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normal_text = normal_text.replace('liberal','',1000).replace('people','',1000).replace('will','',1000)\n",
        "abusive_text = abusive_text.replace('liberal','',1000).replace('people','',1000).replace('will','',1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GXy9WegBJwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normal\n",
        "wordcloud = WordCloud(background_color=\"white\").generate(normal_text)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# abusive\n",
        "wordcloud = WordCloud(background_color=\"white\").generate(abusive_text)\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kCi_RoLE8wP",
        "colab_type": "text"
      },
      "source": [
        "# Split data to X and y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8D_XrHPEaIV",
        "colab_type": "text"
      },
      "source": [
        "Split data to X and y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHcgmnATZA6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_val(train_df, val_df, test_df):\n",
        "    logging.info('splitting X and y ...')\n",
        "    train_X = train_df[\"text\"].fillna(\"_na_\").values\n",
        "    val_X = val_df[\"text\"].fillna(\"_na_\").values\n",
        "    test_X = test_df[\"text\"].fillna(\"_na_\").values\n",
        "\n",
        "    train_y = train_df['label'].values\n",
        "    val_y = val_df['label'].values\n",
        "\n",
        "    logging.info('finished splitting X and y')\n",
        "    return train_X, val_X, test_X, train_y, val_y\n",
        "\n",
        "train_X, val_X, test_X, train_y, val_y = split_train_val(train_df, val_df, test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdk4s-pCZA6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_X.shape, train_y.shape)\n",
        "print(val_X.shape, val_y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feMxvs73D-gx",
        "colab_type": "text"
      },
      "source": [
        "Tokenize and padding each sentence, split datafram to attributes and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNGTN3kVZA6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# each word embedding to 300 dimension\n",
        "embed_size = 300\n",
        "# count of vocabulary words\n",
        "max_features = 50000\n",
        "# length of each sentences\n",
        "max_len = 70\n",
        "\n",
        "def token_sentence(train_X, val_X, test_X ):\n",
        "    logging.info('tokenizing sentence...')\n",
        "    tokenizer = Tokenizer(num_words=max_features)\n",
        "    tokenizer.fit_on_texts(list(train_X))\n",
        "    train_X = tokenizer.texts_to_sequences(train_X)\n",
        "    val_X = tokenizer.texts_to_sequences(val_X)\n",
        "    test_X = tokenizer.texts_to_sequences(test_X)\n",
        "\n",
        "    logging.info('padding sentence...')\n",
        "    train_X = pad_sequences(train_X, maxlen=max_len)\n",
        "    val_X = pad_sequences(val_X, maxlen=max_len)\n",
        "    test_X = pad_sequences(test_X, maxlen=max_len)\n",
        "\n",
        "    logging.info('all finished...')\n",
        "    return train_X, val_X, test_X, tokenizer\n",
        "\n",
        "train_X, val_X, test_X, tokenizer = token_sentence(train_X, val_X, test_X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBUErOp_QEK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AenyxjOSMCDL",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QL2IvlW8qLJQ",
        "colab_type": "text"
      },
      "source": [
        "## Model1: base line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L5EZKeUQgtj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-uZ5egkQd58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYDgYFtKqO40",
        "colab_type": "text"
      },
      "source": [
        "### Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odb9nd5WQST8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dt_model(train_X, train_y, val_X, cal_y):\n",
        "    dt_clf = tree.DecisionTreeClassifier()\n",
        "    dt_clf = dt_clf.fit(train_X, train_y)\n",
        "    pred_val_y = dt_clf.predict(val_X).reshape(-1,1)\n",
        "    dt_acc = accuracy_score(pred_val_y, val_y)\n",
        "    dt_f1_score = f1_score(pred_val_y, val_y)\n",
        "    return dt_acc, dt_f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NbcgKG1RcQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt_acc, dt_f1_score = dt_model(train_X, train_y, val_X, val_y)\n",
        "print('dt_acc: ', dt_acc, ', dt_f1_score: ',  dt_f1_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63QJAP9RqSle",
        "colab_type": "text"
      },
      "source": [
        "### LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-FpKqDpWoiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_model(train_X, train_y, val_X, cal_y):\n",
        "    lr_clf = LogisticRegression(random_state=0, max_iter=4000).fit(train_X, train_y)\n",
        "    pred_val_y = lr_clf.predict(val_X).reshape(-1,1)\n",
        "    lr_acc = accuracy_score(pred_val_y, val_y)\n",
        "    lr_f1_score = f1_score(pred_val_y, val_y)\n",
        "    return lr_acc, lr_f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8B44OR0W_vF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_acc, lr_f1_score = lr_model(train_X, train_y, val_X, val_y)\n",
        "print('lr_acc: ', lr_acc, ', lr_f1_score: ',  lr_f1_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i7BpltoqZza",
        "colab_type": "text"
      },
      "source": [
        "### GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RDWko-oXO9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gNB_model(train_X, train_y, val_X, cal_y):\n",
        "    gNB_clf = GaussianNB()\n",
        "    gNB_clf = gNB_clf.fit(train_X, train_y)\n",
        "    pred_val_y = gNB_clf.predict(val_X).reshape(-1,1)\n",
        "    gNB_acc = accuracy_score(pred_val_y, val_y)\n",
        "    gNB_f1_score = f1_score(pred_val_y, val_y)\n",
        "    return gNB_acc, gNB_f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heu4JLHgX164",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gNB_acc, gNB_f1_score = gNB_model(train_X, train_y, val_X, val_y)\n",
        "print('gNB_acc: ', gNB_acc, ', gNB_f1_score: ',  gNB_f1_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REnqEUw_kKI8",
        "colab_type": "text"
      },
      "source": [
        "## Model2 : LSTM + Without Pretrained Embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9wKqZveyapX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Add an Embedding layer expecting input vocab of size 50000, and\n",
        "# output embedding dimension of size 300.\n",
        "model.add(layers.Embedding(input_dim=50000, output_dim=300))\n",
        "\n",
        "# Add a LSTM layer with 128 internal units.\n",
        "model.add(layers.LSTM(128))\n",
        "model.add(layers.Dense(10,activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71VTQNZjzgn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "callbacks = EarlyStopping(monitor='val_loss', min_delta=0, patience = 2)\n",
        "history = model.fit(train_X, \n",
        "                    train_y, \n",
        "                    batch_size=512, \n",
        "                    epochs=14, \n",
        "                    validation_data=(val_X, val_y),\n",
        "                    callbacks=callbacks\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v_WWWREdP_w",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiaEcGWWZA6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot history\n",
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt \n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "47b63dca0247a08a808db7ae6eea33065c554948",
        "id": "M4y418b5ZA6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation the model(f1-score)\n",
        "pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "print(pred_noemb_val_y)\n",
        "threshes=[]\n",
        "f1_scores=[]\n",
        "accuracy_scores=[]\n",
        "for thresh in np.arange(0.1, 0.801, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    threshes.append(thresh)\n",
        "    logging.info(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
        "    f1_scores.append(metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int)))\n",
        "    print(\"Accuracy at threshold {0} is {1}\".format(thresh, metrics.accuracy_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
        "    accuracy_scores.append(metrics.accuracy_score(val_y, (pred_noemb_val_y>thresh).astype(int)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC0KxHrGnewO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot two measures\n",
        "plt.plot(threshes, f1_scores, color='blue', label='f1')\n",
        "plt.plot(threshes, accuracy_scores, color='orange', label='acc')\n",
        "plt.title('f1_scores/acc')\n",
        "plt.ylabel('f1_scores/acc')\n",
        "plt.xlabel('threshold')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJSYLb3ykxyT",
        "colab_type": "text"
      },
      "source": [
        "## Model3: LSTM + Pretrained embeddings\n",
        "\n",
        "Different Embeddings:\n",
        "\n",
        "GoogleNews-vectors-negative300 - https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "glove.840B.300d - https://nlp.stanford.edu/projects/glove/\n",
        "paragram_300_sl999 - https://cogcomp.org/page/resource_view/106\n",
        "\n",
        "wiki-news-300d-1M - https://fasttext.cc/docs/en/english-vectors.html\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS3iwFGqwHvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "embeddings_index = {}\n",
        "logging.info(\"Loading Glove Model\")\n",
        "with io.open('drive/My Drive/Colab Notebooks/246Project/glove.840B.300d.txt', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = ''.join(values[:-300])\n",
        "        coefs = np.asarray(values[-300:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "logging.info(\"Loading Glove Model Done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7fswnbHDI2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_embs = np.stack(embeddings_index.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "print(all_embs.shape, emb_mean, emb_std, embed_size )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOx2DkzgDS-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "len(word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4Ng8SHSDxBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_words = min(max_features, 1 + len(word_index))\n",
        "nb_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWf0qQ2iD2ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNslPaHb193k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word, i in word_index.items(): \n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: \n",
        "        embedding_matrix[i] = embedding_vector\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RWtEloU2M1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.initializers import Constant\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Embedding(nb_words,\n",
        "                            300,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=max_len,\n",
        "                            trainable=False))\n",
        "model.add(layers.LSTM(128))\n",
        "model.add(layers.Dense(10,activation=\"relu\"))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txx27Bzd3gLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeVa4_2m3kzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "callbacks = EarlyStopping(monitor='val_loss', min_delta=0, patience = 2)\n",
        "\n",
        "history = model.fit(train_X, \n",
        "                    train_y, \n",
        "                    batch_size=512, \n",
        "                    epochs=15, \n",
        "                    validation_data=(val_X, val_y),\n",
        "                    callbacks=callbacks\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JjJbtUNn3cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt \n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AslhlttleNnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# validation the model(f1-score)\n",
        "pred_noemb_val_y = model.predict([val_X], batch_size=1024, verbose=1)\n",
        "print(pred_noemb_val_y)\n",
        "threshes=[]\n",
        "f1_scores=[]\n",
        "accuracy_scores=[]\n",
        "for thresh in np.arange(0.1, 0.801, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    threshes.append(thresh)\n",
        "    logging.info(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
        "    f1_scores.append(metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int)))\n",
        "    print(\"Accuracy at threshold {0} is {1}\".format(thresh, metrics.accuracy_score(val_y, (pred_noemb_val_y>thresh).astype(int))))\n",
        "    accuracy_scores.append(metrics.accuracy_score(val_y, (pred_noemb_val_y>thresh).astype(int)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaSwqigUZA60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot two measures\n",
        "plt.plot(threshes, f1_scores, color='blue', label='f1')\n",
        "plt.plot(threshes, accuracy_scores, color='orange', label='acc')\n",
        "plt.title('f1_scores/acc')\n",
        "plt.ylabel('f1_scores/acc')\n",
        "plt.xlabel('threshold')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "383e51177bf33da0b8fee42dd6a093908b808f64",
        "id": "nGYvEk8EZA6z",
        "colab_type": "text"
      },
      "source": [
        "## Model4: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOh74l0KZA65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logging.info('=========done===========')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX0YxXa_dUJz",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gT0baX2dXqc",
        "colab_type": "text"
      },
      "source": [
        "# Prediction 2\n"
      ]
    }
  ]
}